{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdb5691d-90b6-436a-a135-1a0af5e77690",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78afe591-bf01-4150-a661-25933317218a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:98% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:98% !important; }</style>\"))\n",
    "torch.set_printoptions(linewidth=132)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90747d2c-3ba1-4a8c-98bc-77bc10a8580e",
   "metadata": {},
   "source": [
    "### from https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html\n",
    "# TENSORS\n",
    "### Tensors are a specialized data structure that are very similar to arrays and matrices.\n",
    "### In PyTorch, we use tensors to encode the inputs and outputs of a model, as well as the\n",
    "### model’s parameters.\n",
    "\n",
    "### Tensors are similar to NumPy’s ndarrays, except that tensors can run on GPUs or other\n",
    "### specialized hardware to accelerate computing. If you’re familiar with ndarrays, you’ll\n",
    "### be right at home with the Tensor API. If not, follow along in this quick API walkthrough."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f847f807-33c7-44fd-965e-0a2bbe7cf3ea",
   "metadata": {},
   "source": [
    "### Tensor Initialization\n",
    "### Tensors can be initialized in various ways. Take a look at the following examples:\n",
    "\n",
    "#### Directly from data\n",
    "#### Tensors can be created directly from data. The data type is automatically inferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a2d6685-05c1-4867-abac-771947e00437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [[1, 2], [3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "x_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c05135-7eaa-4d80-b717-ba1495f4c72a",
   "metadata": {},
   "source": [
    "#### From a NumPy array\n",
    "#### Tensors can be created from NumPy arrays (and vice versa - see Bridge with NumPy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdce5c2c-af4f-4461-9c51-53ce566c09f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "x_np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7dc8f9-04a5-458a-be93-79fe9b77fbc4",
   "metadata": {},
   "source": [
    "#### From another tensor:\n",
    "\n",
    "#### The new tensor retains the properties (shape, datatype) of the argument tensor, unless explicitly overridden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b20cb3e1-4884-4757-a729-d9028e0c1bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.9317, 0.0873],\n",
      "        [0.9148, 0.9767]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b00baf-5430-4782-8a14-d8fd749eb4ef",
   "metadata": {},
   "source": [
    "#### With random or constant values:\n",
    "\n",
    "#### shape is a tuple of tensor dimensions. In the functions below, it determines the dimensionality of the output tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b1003b2-225d-49f2-b91b-55aef40b5d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.1613, 0.9591, 0.7060],\n",
      "        [0.1369, 0.4789, 0.0579]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "shape = (2, 3,)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056acbe6-1274-496d-9dd0-de77f603e5ef",
   "metadata": {},
   "source": [
    "### Tensor Attributes\n",
    "Tensor attributes describe their shape, datatype, and the device on which they are stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bc37531-edc6-4971-9754-f75300aea733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.5029, 0.6608, 0.1215, 0.7052],\n",
       "        [0.3918, 0.8027, 0.3394, 0.5618],\n",
       "        [0.2584, 0.1149, 0.0235, 0.6579]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.rand(3, 4)\n",
    "\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58fbed5-5592-4fcc-8868-138ab108d3f2",
   "metadata": {},
   "source": [
    "### Tensor Operations\n",
    "Over 100 tensor operations, including transposing, indexing, slicing, mathematical operations, linear algebra, random sampling, and more are comprehensively described at: https://pytorch.org/docs/stable/torch.html.<br>\n",
    "\n",
    "Each of them can be run on the GPU (at typically higher speeds than on a CPU). If you’re using Colab, allocate a GPU by going to Edit > Notebook Settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a16963fa-da8e-41ba-82bc-f5c5cf8396e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device tensor is stored on CPU\n"
     ]
    }
   ],
   "source": [
    "# We move our tensor to the GPU if available\n",
    "if torch.cuda.is_available():\n",
    "  tensor = tensor.to('cuda')\n",
    "  print(f\"Device tensor is stored on: {tensor.device}\")\n",
    "else:\n",
    "  print(f\"Device tensor is stored on CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33109f34-2e26-48f2-9f69-46b2ebe25e59",
   "metadata": {},
   "source": [
    "#### Try out some of the operations from the list. If you’re familiar with the NumPy API, you’ll find the Tensor API a breeze to use.\n",
    "#### Standard numpy-like indexing and slicing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c784521-e698-4959-bb8c-419fb17a7338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.ones(4, 4)\n",
    "tensor[:,1] = 0\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1517e61b-b0e8-41b9-8eae-6ce3edef292c",
   "metadata": {},
   "source": [
    "#### Joining tensors\n",
    "You can use torch.cat to concatenate a sequence of tensors along a given dimension. See also torch.stack, another tensor joining op that is subtly different from torch.cat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b3c106d-12e1-48f9-8f61-2743c05c5605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.00, 0.00, 1.00, 1.00, 0.42, 0.73, 0.80, 0.81, 1.00, 0.00, 1.00, 1.00],\n",
       "        [1.00, 0.00, 1.00, 1.00, 0.27, 1.00, 0.85, 0.94, 1.00, 0.00, 1.00, 1.00],\n",
       "        [1.00, 0.00, 1.00, 1.00, 0.49, 0.52, 0.02, 0.59, 1.00, 0.00, 1.00, 1.00],\n",
       "        [1.00, 0.00, 1.00, 1.00, 0.68, 0.81, 0.80, 0.47, 1.00, 0.00, 1.00, 1.00]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = torch.cat([tensor, torch.rand(4, 4), tensor], dim=1)\n",
    "t1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494682c8-6d68-4663-abc7-5bf2134ea2b7",
   "metadata": {},
   "source": [
    "#### Multiplying tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1bfbf50-7b65-43d4-ade7-4a3a05e62d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor.mul(tensor) \n",
      " tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]]) \n",
      "\n",
      "tensor * tensor \n",
      " tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# This computes the element-wise product\n",
    "print(f\"tensor.mul(tensor) \\n {tensor.mul(tensor)} \\n\")\n",
    "# Alternative syntax:\n",
    "print(f\"tensor * tensor \\n {tensor * tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc9c733-ebd0-486f-a4a3-c3d64fd81f75",
   "metadata": {},
   "source": [
    "#### Matrix multiplication between two tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c276d3c-1b9f-455d-9401-ebe200464f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor.matmul(tensor.T) \n",
      " tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]]) \n",
      "\n",
      "tensor @ tensor.T \n",
      " tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"tensor.matmul(tensor.T) \\n {tensor.matmul(tensor.T)} \\n\")\n",
    "# Alternative syntax:\n",
    "print(f\"tensor @ tensor.T \\n {tensor @ tensor.T}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19df8afc-2faa-4fc6-8974-d9a8a530a2e7",
   "metadata": {},
   "source": [
    "#### In-place operations Operations that have a _ suffix are in-place. For example: x.copy_(y), x.t_(), will change x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a1374db9-c52f-4414-ba53-85d2dacc3e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]]) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[6., 5., 6., 6.],\n",
       "        [6., 5., 6., 6.],\n",
       "        [6., 5., 6., 6.],\n",
       "        [6., 5., 6., 6.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE:\n",
    "\n",
    "#In-place operations save some memory, but can be problematic when computing derivatives because of an immediate loss of history.\n",
    "# Hence, their use is discouraged.\n",
    "\n",
    "\n",
    "print(tensor, \"\\n\")\n",
    "tensor.add_(5)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23982ce-4330-48ef-867e-8c02950a93b6",
   "metadata": {},
   "source": [
    "#### Bridge with NumPy\n",
    "Tensors on the CPU and NumPy arrays can share their underlying memory locations, and changing one will change the other.\n",
    "\n",
    "#### Tensor to NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a4f79a66-c5ff-4ef1-be7a-b24463eac7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor t: tensor([1., 1., 1., 1., 1.])\n",
      "numpy n: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones(5)\n",
    "print(f\"tensor t: {t}\")\n",
    "n = t.numpy()\n",
    "print(f\"numpy n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5baa8293-a865-483d-8ebb-bb7e67fb27f6",
   "metadata": {},
   "source": [
    "#### A change in the tensor reflects in the NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "021d0d0f-adb4-4790-a288-745f4f6eb7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.])\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "t.add_(1)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333ed123-9725-4ec1-b608-588cbe3d072d",
   "metadata": {},
   "source": [
    "#### NumPy array to Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "00ccfe20-6e8e-49a4-9bf9-c015e3485f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "n: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29df4088-1153-494e-97ca-6ed254318543",
   "metadata": {},
   "source": [
    "#### Changes in the NumPy array reflects in the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "78591c4e-6bf0-4695-85d4-68a99bb0f668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "np.add(n, 1, out=n)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a36342-a254-4ba3-8e77-b1b39c006002",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
